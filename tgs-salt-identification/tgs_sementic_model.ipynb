{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of tgs_sementic_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS7v2aHGvCZQ",
        "colab_type": "text"
      },
      "source": [
        "# **TGS SALT IDENTIFICATION CHALLENGE**\n",
        "\n",
        "# **Segment salt deposits beneath the Earth's surface**\n",
        "\n",
        "Several areas of Earth with large accumulations of oil and gas also have huge deposits of salt below the surface.\n",
        "\n",
        "But unfortunately, knowing where large salt deposits are precisely is very difficult. Professional seismic imaging still requires expert human interpretation of salt bodies. This leads to very subjective, highly variable renderings. More alarmingly, it leads to potentially dangerous situations for oil and gas company drillers.\n",
        "\n",
        "The task is to build an algorithm that automatically and accurately identifies if a subsurface target is salt or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKwBeOtVqH_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import image\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from skimage.transform import resize\n",
        "import sys\n",
        "from keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-fFnd2cxRJs",
        "colab_type": "text"
      },
      "source": [
        "# **Loading and Resizing training images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0zPQ9GmX54N",
        "colab_type": "code",
        "outputId": "cd539824-b6aa-4769-f5b5-4b3d43e41640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93,
          "referenced_widgets": [
            "0f54dfd015bb4105897f63f6224117a5"
          ]
        }
      },
      "source": [
        "\n",
        "path = \"tgs_data/train\"\n",
        "PATH_TRAIN =\"tgs_data/train/images\"\n",
        "PATH_TEST = \"tgs_data/test/images\"\n",
        "train_ids = os.listdir(PATH_TRAIN)\n",
        "test_ids = os.listdir(PATH_TEST)\n",
        "\n",
        "print (len(train_ids))\n",
        "\n",
        "im_width = 128\n",
        "im_height = 128\n",
        "im_chan = 1\n",
        "\n",
        "X_train = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
        "Y_train = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.bool)\n",
        "print('Getting and resizing train images and masks ')\n",
        "sys.stdout.flush()\n",
        "for n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n",
        "    path = \"tgs_data/train\"\n",
        "    img = load_img(path + '/images/' + id_)\n",
        "    x = img_to_array(img)[:,:,1]\n",
        "    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n",
        "    X_train[n] = x\n",
        "    mask = img_to_array(load_img(path + '/masks/' + id_))[:,:,1]\n",
        "    Y_train[n] = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n",
        "\n",
        "print('Finished resizing!')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4000\n",
            "Getting and resizing train images and masks ... \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f54dfd015bb4105897f63f6224117a5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNWBUstsxaty",
        "colab_type": "text"
      },
      "source": [
        "# **Displaying a resized-training image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4s_Xcf8muha",
        "colab_type": "code",
        "outputId": "f069ec4a-2c64-4f43-e4bb-8a51754f3266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "a = array_to_img(X_train[10])\n",
        "a\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAAjxElEQVR4nD27265ky7IkZObuEWNk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\nykRizugNx5B7bI7crR//P4M1C/+LZRYxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7F23E6509DA0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_q5DdAfxZBp",
        "colab_type": "text"
      },
      "source": [
        "# **Mean_IOU**\n",
        "An evaluation metric for semantic image segmentation, which first computes the IOU for each semantic class and then computes the average over classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McKcXbYCYOih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_iou(y_true, y_pred):\n",
        "    prec = []\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        y_pred_ = tf.to_int32(y_pred > t)\n",
        "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([up_opt]):\n",
        "            score = tf.identity(score)\n",
        "        prec.append(score)\n",
        "    return K.mean(K.stack(prec), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0N52bZbU4Qo",
        "colab_type": "text"
      },
      "source": [
        "# **U-NET Model**\n",
        "The implementation of U-Net model. It is regarded as one of the best architectures for image segmentation.\n",
        " \n",
        "Link to original paper: https://arxiv.org/pdf/1505.04597.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4LwIoh5YSZ4",
        "colab_type": "code",
        "outputId": "b812be7f-6c64-4303-87da-ed21eadc62e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "inputs = Input((im_height, im_width, im_chan))\n",
        "s = Lambda(lambda x: x / 255) (inputs)\n",
        "\n",
        "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\n",
        "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
        "p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
        "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
        "p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
        "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
        "p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
        "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
        "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\n",
        "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n",
        "\n",
        "u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "u6 = concatenate([u6, c4])\n",
        "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
        "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
        "\n",
        "u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "u7 = concatenate([u7, c3])\n",
        "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n",
        "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n",
        "\n",
        "u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "u8 = concatenate([u8, c2])\n",
        "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n",
        "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n",
        "\n",
        "u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "u9 = concatenate([u9, c1], axis=3)\n",
        "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n",
        "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n",
        "\n",
        "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "model = Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 128, 128, 1)  0           input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 128, 128, 8)  80          lambda_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 128, 128, 8)  584         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling2D) (None, 64, 64, 8)    0           conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 64, 64, 16)   1168        max_pooling2d_29[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling2D) (None, 32, 32, 16)   0           conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 32, 32, 32)   4640        max_pooling2d_30[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 32, 32, 32)   9248        conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling2D) (None, 16, 16, 32)   0           conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18496       max_pooling2d_31[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 64)   36928       conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling2D) (None, 8, 8, 64)     0           conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 8, 8, 128)    73856       max_pooling2d_32[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 8, 8, 128)    147584      conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_20 (Conv2DTran (None, 16, 16, 64)   32832       conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 128)  0           conv2d_transpose_20[0][0]        \n",
            "                                                                 conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 64)   73792       concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_21 (Conv2DTran (None, 32, 32, 32)   8224        conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 32, 32, 64)   0           conv2d_transpose_21[0][0]        \n",
            "                                                                 conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 32, 32, 32)   18464       concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 32, 32, 32)   9248        conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_22 (Conv2DTran (None, 64, 64, 16)   2064        conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 64, 64, 32)   0           conv2d_transpose_22[0][0]        \n",
            "                                                                 conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 64, 64, 16)   4624        concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_23 (Conv2DTran (None, 128, 128, 8)  520         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 128, 128, 16) 0           conv2d_transpose_23[0][0]        \n",
            "                                                                 conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 128, 128, 8)  1160        concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 128, 128, 8)  584         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 128, 128, 1)  9           conv2d_127[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 448,745\n",
            "Trainable params: 448,745\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVDyF9jAWnvX",
        "colab_type": "text"
      },
      "source": [
        "# **Training over the data and plotting loss and accuracy graphs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk8sYMz5YWkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
        "checkpointer = ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True)\n",
        "history = model.fit(X_train, Y_train, validation_split=0.25, epochs=50, \n",
        "                    callbacks=[earlystopper, checkpointer])\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['mean_iou'])\n",
        "plt.plot(history.history['val_mean_iou'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('mean IOU')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "model.save('tgs_data.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}